{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c280572c",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f69591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce1c147",
   "metadata": {},
   "source": [
    "### Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf791a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame's from raw csv data\n",
    "df_features = pd.read_csv('../data/raw/coral_multilabel_dataset.csv')\n",
    "df_annotations = pd.read_csv('../data/raw/metadata_annotations.csv')\n",
    "df_regions = pd.read_csv('../data/raw/metadata_regions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996e2c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect df_features\n",
    "duplicate_count = df_features['image_id'].duplicated().sum()\n",
    "null_count = df_features.isnull().sum().sum()\n",
    "n_rows = len(df_features)\n",
    "print(f\"Duplicate image_ids: {duplicate_count}\")\n",
    "print(f\"Total null values: {null_count}\")\n",
    "print(f'Total rows: {n_rows}')\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4ac088",
   "metadata": {},
   "source": [
    "There are no duplicate images or null values in this dataset. We can see there are 4821 rows (images) and 172 columns (image_id + benthic attributes) in the dataset. The benthic attributes are binary features. We will want to drop image_id for EDA purposes, leaving us with 171 benthic attributes to filter through."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600b6018",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "\n",
    "#### Label-Aware Filtering\n",
    "We don't want to overload our CNN's or Vision Transformer with too many benthic attributes to try to learn.  In order to keep the labels to train the model on under ~30, we will select features that appear at least 100 times in the image collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc24235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature columns without 'image_id' \n",
    "feature_cols = df_features.columns.drop(['image_id']) \n",
    "# Label counts for each benthic attribute \n",
    "label_counts = df_features[feature_cols].sum() \n",
    "# Only keep counts with at least 100 positive examples \n",
    "filtered_labels = label_counts[label_counts >= 100].sort_values(ascending=False) \n",
    "# DataFrame of filtered labels + counts print(f'Attributes ≥100 positives: {len(filtered_labels)}') \n",
    "filtered_labels.to_frame(name=\"positive_count\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d4d07d",
   "metadata": {},
   "source": [
    "We identified 25 benthic attributes with at least 100 positive examples. One of these is the “Other” category. Since “Other” represents everything outside the full set of 171 benthic attributes, it does not provide meaningful ecological information for our reduced feature set. Because of this, we will exclude it from our modeling subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed3e734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'Other' attribute\n",
    "if 'Other' in filtered_labels.index:\n",
    "    filtered_labels = filtered_labels.drop('Other')\n",
    "\n",
    "print(f'Attributes ≥100 positives (excluding \"Other\"): {len(filtered_labels)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8535788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before vs After Label-Aware Filtering: Side-by-Side Subplots\n",
    "\n",
    "initial_counts = df_features[feature_cols].sum()\n",
    "after_counts = label_counts[filtered_labels.index]\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Subplot 1: BEFORE FILTERING\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(initial_counts.values, bins=15, color='steelblue', edgecolor='black')\n",
    "plt.title(\"Label Count Distribution (Before Filtering)\")\n",
    "plt.xlabel(\"Positive Count\")\n",
    "plt.ylabel(\"Number of Labels\")\n",
    "\n",
    "# Subplot 2: AFTER FILTERING\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(after_counts.values, bins=15, color='seagreen', edgecolor='black')\n",
    "plt.title(\"Label Count Distribution (After Filtering)\")\n",
    "plt.xlabel(\"Positive Count\")\n",
    "plt.ylabel(\"Number of Labels\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95285a1",
   "metadata": {},
   "source": [
    "#### Region-Aware Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7501e63e",
   "metadata": {},
   "source": [
    "Our goal is to evaluate the model on a geographic region it has never seen during training. For this to work, each region must contain enough examples of the benthic attributes we plan to model. Before deciding which features to keep, we examine the region metadata to understand how these attributes are distributed across regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65ea67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge features with regions so each image has its region_name\n",
    "df_merged = df_features.merge(\n",
    "    df_regions[['image_id', 'region_name']],\n",
    "    on='image_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Compute counts of filtered_labels per region\n",
    "region_label_counts = (\n",
    "    df_merged.groupby('region_name')[filtered_labels.index]\n",
    "    .sum()\n",
    "    .T   # transpose: labels = rows, regions = columns\n",
    ")\n",
    "\n",
    "# Total positives per region across all filtered labels\n",
    "region_positive_counts = region_label_counts.sum(axis=0)\n",
    "\n",
    "# Proportion of all filtered-label positives that come from each region\n",
    "region_positive_props = region_positive_counts / region_positive_counts.sum()\n",
    "\n",
    "print(\"Proportion of filtered-label positives by region:\\n\")\n",
    "print(region_positive_props)\n",
    "\n",
    "region_label_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35823b11",
   "metadata": {},
   "source": [
    "Central Indo-Pacific accounts for roughly 55.7 percent of the dataset, Western Indo-Pacific for 43.6 percent, and the Tropical Atlantic for less than 1 percent. Because of this distribution, using Western Indo-Pacific as the test region is reasonable, since the model can train on the larger Central Indo-Pacific subset. The table above also shows that several benthic attributes have very low or no overlap between these regions, so additional feature filtering is be necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb392b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region Composition Visualization\n",
    "plt.figure(figsize=(6, 4))\n",
    "region_positive_props.sort_values().plot(kind='barh')\n",
    "\n",
    "plt.title(\"Proportion of Filtered-Label Positives by Region\")\n",
    "plt.xlabel(\"Proportion\")\n",
    "plt.ylabel(\"Region\")\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352671d1",
   "metadata": {},
   "source": [
    "We choose a minimum of 100 positive examples per region to ensure each benthic attribute has enough representation for CNNs and Vision Transformers to learn meaningful visual patterns and generalize across geographic regions. It’s acceptable to exclude the Tropical Atlantic because it represents less than one percent of the dataset, so it cannot provide enough examples to support meaningful model training or region-based evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e69facf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-region minimum threshold\n",
    "min_per_region = 100  \n",
    "\n",
    "major_regions = ['Central Indo-Pacific', 'Western Indo-Pacific']\n",
    "\n",
    "region_filtered = region_label_counts.loc[\n",
    "    (region_label_counts[major_regions] >= min_per_region).all(axis=1)\n",
    "]\n",
    "\n",
    "# Heatmap of Positive Counts Across Regions\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(region_filtered, annot=True, fmt='d', cmap='Blues')\n",
    "\n",
    "plt.title(\"Positive Counts per Benthic Attribute Across Regions\")\n",
    "plt.xlabel(\"Region\")\n",
    "plt.ylabel(\"Benthic Attribute\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21edbd4",
   "metadata": {},
   "source": [
    "#### Check for Label Co-Occurrence Structure\n",
    "\n",
    "We check for co-occurrence to ensure that no two benthic attributes always appear together, which would make them redundant and prevent the model from learning distinct visual patterns for each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93433aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix for the final region-filtered labels\n",
    "co_occurrence = df_features[region_filtered.index].corr()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(co_occurrence, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title(\"Correlation Between Selected Benthic Attributes\")\n",
    "plt.show()\n",
    "\n",
    "# Count correlations above threshold (excluding diagonal)\n",
    "high_corr_mask = (co_occurrence.abs() > 0.90)\n",
    "high_corr_count = high_corr_mask.sum() - 1   # subtract diagonal\n",
    "\n",
    "# Find high-correlation pairs\n",
    "high_corr_pairs = [\n",
    "    (i, j, co_occurrence.loc[i, j])\n",
    "    for i in co_occurrence.index\n",
    "    for j in co_occurrence.columns\n",
    "    if i < j and abs(co_occurrence.loc[i, j]) > 0.90\n",
    "]\n",
    "\n",
    "# Print result\n",
    "if len(high_corr_pairs) == 0:\n",
    "    print(\"No high correlation pairs found.\")\n",
    "else:\n",
    "    print(\"High correlation pairs (>0.90):\")\n",
    "    for pair in high_corr_pairs:\n",
    "        print(pair)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62111c0a",
   "metadata": {},
   "source": [
    "#### Per-Region Negative Counts\n",
    "\n",
    "We check per-region negative counts to ensure the model sees both the presence and absence of each benthic attribute, since a label cannot be learned reliably if it never appears as a negative example in a region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72206036",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_neg_counts = df_merged.groupby('region_name')[region_filtered.index] \\\n",
    "                             .apply(lambda x: (x == 0).sum())\n",
    "\n",
    "# Heatmap of Negative Counts Across Regions\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(region_neg_counts, annot=True, fmt='d', cmap='Reds')\n",
    "\n",
    "plt.title(\"Negative Counts per Benthic Attribute Across Regions\")\n",
    "plt.xlabel(\"Region\")\n",
    "plt.ylabel(\"Benthic Attribute\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d63483",
   "metadata": {},
   "source": [
    "In our dataset, both major regions contain substantial negative counts for all selected attributes, which confirms that each label provides a meaningful learning signal and can be distinguished reliably across regions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf90da7",
   "metadata": {},
   "source": [
    "#### Prevalence Distribution\n",
    "\n",
    "We examine the prevalence of each attribute to detect extremely rare or overly common labels that could cause imbalance during training or skew evaluation metrics. This is especially important for multi-label deep learning because extreme imbalance can cause unstable training, biased gradients and poor recall on rare classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3921e71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate prevalence for each selected label (proportion of images where label==1)\n",
    "prevalence = df_features[region_filtered.index].mean().sort_values(ascending=False)\n",
    "\n",
    "# Convert to percent for easier interpretation\n",
    "prevalence_percent = (prevalence * 100).round(2)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=prevalence_percent.values, y=prevalence_percent.index)\n",
    "\n",
    "plt.xlabel(\"Prevalence (% of images)\")\n",
    "plt.ylabel(\"Benthic Attribute\")\n",
    "plt.title(\"Prevalence of Selected Benthic Attributes\")\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "prevalence_percent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dc3b68",
   "metadata": {},
   "source": [
    "Most benthic attributes show moderate to high prevalence across the dataset, while even the rarest remaining classes appear in more than five percent of images, suggesting that the final feature set does not suffer from extreme imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f43e69",
   "metadata": {},
   "source": [
    "### Annotation Consistency Check\n",
    "\n",
    "We want to check annotation-level consistency to ensure that the image-level benthic attributes correspond to what is present in the point-level annotation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e10d4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ecological reliability check \n",
    "annotation_counts = df_annotations['benthic_attribute_name'].value_counts()\n",
    "\n",
    "final_labels = region_filtered.index\n",
    "annotation_final = annotation_counts.reindex(final_labels).fillna(0)\n",
    "\n",
    "image_level_counts = label_counts.reindex(final_labels)\n",
    "\n",
    "consistency_df = pd.DataFrame({\n",
    "    \"image_level_positives\": image_level_counts,\n",
    "    \"annotation_points\": annotation_final.astype(int)\n",
    "}).sort_values(by=\"image_level_positives\", ascending=False)\n",
    "\n",
    "print(\"Image-level vs Annotation-level counts:\\n\")\n",
    "print(consistency_df)\n",
    "\n",
    "low_annotation_labels = consistency_df[consistency_df['annotation_points'] < 20]\n",
    "\n",
    "if len(low_annotation_labels) == 0:\n",
    "    print(\"\\nNo annotation inconsistencies detected (annotation_points ≥ 20).\")\n",
    "else:\n",
    "    print(\"\\nPotential annotation inconsistencies (annotation_points < 20):\")\n",
    "    display(low_annotation_labels)\n",
    "\n",
    "\n",
    "# Logical consistency check (annotation ≥ image)\n",
    "consistency_df[\"annotation_ge_image\"] = (\n",
    "    consistency_df[\"annotation_points\"] >= consistency_df[\"image_level_positives\"]\n",
    ")\n",
    "\n",
    "if consistency_df[\"annotation_ge_image\"].all():\n",
    "    print(\"\\nAll labels are logically consistent: annotation_points >= image_level_positives.\")\n",
    "else:\n",
    "    print(\"\\nLogical inconsistency detected. These labels violate annotation >= image rule:\")\n",
    "    display(consistency_df[~consistency_df[\"annotation_ge_image\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af875f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotation vs Image-Level Comparison\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.scatter(\n",
    "    consistency_df[\"image_level_positives\"],\n",
    "    consistency_df[\"annotation_points\"],\n",
    "    s=60\n",
    ")\n",
    "\n",
    "for label in consistency_df.index:\n",
    "    x = consistency_df.loc[label, \"image_level_positives\"]\n",
    "    y = consistency_df.loc[label, \"annotation_points\"]\n",
    "    plt.text(x, y, label, fontsize=8)\n",
    "\n",
    "plt.xlabel(\"Image-Level Positives\")\n",
    "plt.ylabel(\"Annotation Points\")\n",
    "plt.title(\"Annotation Points vs Image-Level Positives\")\n",
    "plt.grid(alpha=0.4)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c968fd",
   "metadata": {},
   "source": [
    "This scatter plot compares the number of image-level positives to the number of point-level annotations for each selected attribute, and the upward-right trend shows that attributes with more positive images also have more supporting annotation points, indicating strong and consistent ecological labeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128f54f0",
   "metadata": {},
   "source": [
    "### Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc700934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create processed directory if not exists\n",
    "import os\n",
    "os.makedirs(\"../data/processed\", exist_ok=True)\n",
    "\n",
    "# Final labels list \n",
    "final_label_cols = [\"image_id\"] + list(final_labels)\n",
    "\n",
    "# Build a dataframe that contains image_id + region_name + selected labels\n",
    "final_df = df_merged[[\"image_id\", \"region_name\"] + list(final_labels)]\n",
    "\n",
    "# Define regions\n",
    "test_region = \"Western Indo-Pacific\"\n",
    "train_regions = [\"Central Indo-Pacific\", \"Tropical Atlantic\"]\n",
    "\n",
    "# Create datasets\n",
    "df_full = df_features[final_label_cols]\n",
    "df_train = final_df[final_df[\"region_name\"].isin(train_regions)].reset_index(drop=True)\n",
    "df_test = final_df[final_df[\"region_name\"] == test_region].reset_index(drop=True)\n",
    "\n",
    "# Save datasets\n",
    "df_full.to_csv(\"../data/processed/final_labels_full.csv\",index=False)\n",
    "df_train.to_csv(\"../data/processed/final_labels_train.csv\", index=False)\n",
    "df_test.to_csv(\"../data/processed/final_labels_test.csv\", index=False)\n",
    "\n",
    "print(\"Processed EDA outputs saved to ../data/processed/\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coral-reef-classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
